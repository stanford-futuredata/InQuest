"""
Classes that implement different sampling strategies.
"""
from query.query import QueryType

from abc import ABC, abstractmethod
from typing import List

import numpy as np
import pandas as pd

import json
import random


class BaseSampling(ABC):
    """
    An abstract base class for our candidate sampling logic.
    """

    def __init__(self):
        """
        No base initialization.
        """
        pass

    @abstractmethod
    def sample(self, proxy_pred, oracle_pred):
        """
        The abstract method that executes sampling strategy. The function
        takes in the proxy and oracle prediction(s) (if the oracle was sampled)
        and returns a final prediction for this sample
        """
        pass


class RandomSampling(BaseSampling):
    """
    An implementation of the sampling logic that returns a value in {0, 1}
    according to a specified sample probability. If the oracle was sampled
    for this frame then it returns the oracle prediction.
    """
    def __init__(self, sample_prob):
        """
        Initialize sample probability threshold.
        """
        self.sample_prob = sample_prob

    def sample(self, proxy_pred, oracle_pred):
        """
        If the oracle wasn't sampled, then return prediction according to the
        sampling probability. Otherwise, return the oracle prediction.
        """
        if oracle_pred is not None:
            return oracle_pred

        return int(random.random() > self.sample_prob)


class ProxyThresholdSampling(BaseSampling):
    """
    An implementation of the sampling logic that returns a value in {0, 1}
    depending on whether the proxy prediction exceeds the given threshold.
    If the oracle was sampled for this frame then it returns the oracle
    prediction.
    """
    def __init__(self, proxy_prob_threshold):
        """
        Initialize proxy probability threshold.
        """
        self.proxy_prob_threshold = proxy_prob_threshold

    def sample(self, proxy_pred, oracle_pred):
        """
        If the oracle wasn't sampled, then return 1 if the current frame's
        proxy probability exceeds the threshold. Otherwise, return the frame's
        oracle prediction.
        """
        if oracle_pred is not None:
            return oracle_pred

        return int(proxy_pred > self.proxy_prob_threshold)


class ProxyPassThroughSampling(BaseSampling):
    """
    An implementation of the candidate sampling logic that simply passes
    through the proxy prediction unless the oracle was sampled, in which case
    it returns the oracle prediction.
    """

    def sample(self, proxy_pred, oracle_pred):
        """
        Return the proxy prediction if the oracle was not sampled, otherwise
        return the oracle prediction.
        """
        return proxy_pred if oracle_pred is None else oracle_pred


# class UniformStratifiedSampling(BaseSampling):
#     """
#     An implementation that naively samples in a stratified fashion uniformly throughout time
#     """

#     def __init__(self, query, sampling_config, agg_config):
#         # compute uniformly spaced frames
#         step = 1 if "subsample" not in sampling_config else sampling_config['subsample']
#         frames = np.arange(query.start_frame, query.end_frame + 1, step)

#         self.frames_to_sample = set(np.random.choice(
#             frames,
#             size=min(query.oracle_limit, len(frames)),
#             replace=False,
#         ))
#         self.agg_config = agg_config

#         # lists to contain samples and whether or not they match the predicate
#         self.samples = []
#         self.samples_match_predicate = []

#     def compute_prediction(self):
#         """
#         Return the predicted answer(s) to the given query.
#         """
#         # get samples matching predicate
#         samples = self.get_samples()

#         prediction = None
#         if self.agg_config['function'] == "mean":
#             prediction = np.nanmean(samples)

#         elif self.agg_config['function'] == "sum":            
#             prediction = np.sum(samples)

#         return prediction, samples, sorted(list(self.frames_to_sample))

#     def get_samples(self):
#         """
#         Return the samples generated by the sampling strategy; filter for
#         the samples that actually match the predicate.
#         """
#         samples = []
#         for idx, sample in enumerate(self.samples):
#             matches_predicate = self.samples_match_predicate[idx]

#             # keep sample if it matches the predicate
#             if matches_predicate:
#                 samples.append(sample)

#         return samples
    
#     def sample(self, proxy_pred, oracle_pred, oracle_matches_predicate, frame):
#         """
#         Sample the frame if it is in frames_to_sample
#         """
#         if frame in self.frames_to_sample:
#             self.samples.append(oracle_pred)
#             self.samples_match_predicate.append(oracle_matches_predicate)


class UniformSampling(BaseSampling):
    """
    An implementation that naively samples in uniform fashion throughout time
    """

    def __init__(self, query, sampling_config, agg_config):
        # compute uniformly spaced frames
        step = 1 if "subsample" not in sampling_config else sampling_config['subsample']
        frames = np.arange(query.start_frame, query.end_frame + 1, step)
        self.frames_to_sample = set(np.random.choice(
            frames,
            size=min(query.oracle_limit, len(frames)),
            replace=False,
        ))
        self.agg_config = agg_config

        # lists to contain samples and whether or not they match the predicate
        self.samples = []
        self.samples_match_predicate = []

    def compute_prediction(self, trial_idx):
        """
        Return the predicted answer(s) to the given query.
        """
        # get samples matching predicate
        samples = self.get_samples()

        prediction = None
        if self.agg_config['function'] == "mean":
            prediction = np.nanmean(samples) if len(samples) > 0 else 0

        elif self.agg_config['function'] == "sum":            
            prediction = np.sum(samples) if len(samples) > 0 else 0

        return prediction

    def get_samples(self):
        """
        Return the samples generated by the sampling strategy; filter for
        the samples that actually match the predicate.
        """
        samples = []
        for idx, sample in enumerate(self.samples):
            matches_predicate = self.samples_match_predicate[idx]

            # keep sample if it matches the predicate
            if matches_predicate:
                samples.append(sample)

        return samples
    
    def sample(self, proxy_pred, oracle_pred, oracle_matches_predicate, frame):
        """
        Sample the frame if it is in frames_to_sample
        """
        if frame in self.frames_to_sample:
            self.samples.append(oracle_pred)
            self.samples_match_predicate.append(oracle_matches_predicate)


class ABaeSampling(BaseSampling):
    """
    A first attempt at implementing ABae in a streaming fashion. This class maintains
    all of the sampling logic and outputs a weighted avg. prediction in a fashion
    meant to mimic that of ABae.
    """

    def __init__(
        self,
        strata: List[float],
        prior: List[float],
        oracle_budget: int,
        query: QueryType,
        alpha: float,
        warm_up_frac: float,
        epsilon: float=0.000001,
        min_prior_per_strata: int=3,
        min_dynamic_sample_prob: float=0.01,
    ):
        """
        Initialize state needed to replicate ABae logic.
        """
        assert len(strata) == len(prior)

        self.K = len(strata)
        self.strata = sorted(strata)  # sort in increasing order if not already done
        self.prior = prior
        self.budget = oracle_budget
        self.prior_budget = max(round((1 - alpha) * oracle_budget), min_prior_per_strata * self.K)
        self.dynamic_budget = self.budget - self.prior_budget
        self.alpha = alpha
        self.min_dynamic_sample_prob = min_dynamic_sample_prob
        self.warm_up_end_frame = query.start_frame + round(warm_up_frac * (query.end_frame - query.start_frame))
        self.end_frame = query.end_frame
        self.counts = [0 for _ in range(self.K)]
        self.means = [0 for _ in range(self.K)]
        self.stds = [0 for _ in range(self.K)]
        self.epsilon = epsilon

        # list of samples to maintain for each strata
        self.warmup_samples = [[] for _ in range(self.K)]
        self.warmup_samples_match_predicate = [[] for _ in range(self.K)]
        self.dynamic_samples = [[] for _ in range(self.K)]
        self.dynamic_samples_match_predicate = [[] for _ in range(self.K)]

        # initialize subset of budget based on prior
        self.prior_samples_per_strata = [
            max(min_prior_per_strata, int(np.floor(self.prior_budget * strata_prior)))
            for strata_prior in self.prior
        ]

        # initialize empty variables that need to be re-created on each call to sample()
        self.dynamic_samples_per_strata = None

        # initialize self.pos_rate_per_strata before first call to sample()
        self.pos_rate_per_strata = None

    def compute_means_and_stds(self) -> None:
        """
        Compute the statistic mean and standard deviation for positive samples
        per strata.
        """
        # get samples matching predicate
        samples, _, _ = self.get_samples()

        for strata_idx in range(self.K):
            self.means[strata_idx] = (
                np.mean(samples[strata_idx])
                if len(samples[strata_idx]) > 0
                else 0
            )

            self.stds[strata_idx] = (
                np.std(samples[strata_idx], ddof=1)
                if len(samples[strata_idx]) > 1
                else 0
            )

    def compute_pos_rates(self, smooth=True) -> None:
        """
        Compute the positive sample rates per strata.
        """
        # get samples matching predicate
        _, hits, sampled = self.get_samples()
        
        if smooth:
            self.pos_rate_per_strata = [
                (1 + hits[strata_idx])/(1 + sampled[strata_idx])
                for strata_idx in range(self.K)
            ]
        else:
            self.pos_rate_per_strata = [
                hits[strata_idx] / sampled[strata_idx] if sampled[strata_idx] > 0 else 0
                for strata_idx in range(self.K)
            ]

    def compute_dynamic_samples_per_strata(self) -> None:
        """
        Compute the number of samples per strata.
        """
        # compute strata weights and total weight
        strata_weights = [
            np.sqrt(self.pos_rate_per_strata[strata_idx]) * self.stds[strata_idx] + self.epsilon
            for strata_idx in range(self.K)
        ]

        total_weight = np.sum(strata_weights)

        # compute dynamic samples per strata
        self.dynamic_samples_per_strata = [
            np.floor(self.dynamic_budget * (strata_weights[strata_idx]/total_weight))
            for strata_idx in range(self.K)
        ]

        # add back floored out samples
        if sum(self.dynamic_samples_per_strata) < self.dynamic_budget:
            num_samples = int(self.dynamic_budget - sum(self.dynamic_samples_per_strata))
            indices = np.random.choice(np.arange(self.K), size=num_samples, replace=False)

            for strata_idx in indices:
                self.dynamic_samples_per_strata[strata_idx] += 1

    def compute_prediction(self) -> float:
        """
        Compute the final prediction to be returned
        """
        # compute strata positive rates w/smoothing off
        self.compute_pos_rates(smooth=False)

        # compute final means
        self.compute_means_and_stds()

        total_pos_rate = np.sum(self.pos_rate_per_strata)
        prediction = 0
        for strata_idx in range(self.K):
            prediction += self.means[strata_idx] * (self.pos_rate_per_strata[strata_idx]/total_pos_rate)

        # TODO: make this work for sum in addition to mean

        return prediction
    
    def get_samples(self):
        """
        Return the samples generated by the sampling strategy; filter for
        the samples that actually match the predicate.
        """
        samples = [[] for _ in range(self.K)]
        hits = [0 for _ in range(self.K)]
        sampled = [0 for _ in range(self.K)]
        for strata_idx in range(self.K):
            # collect strata samples
            strata_samples = self.warmup_samples[strata_idx] + self.dynamic_samples[strata_idx]
            strata_samples_match_predicate = self.warmup_samples_match_predicate[strata_idx] + self.dynamic_samples_match_predicate[strata_idx]

            # get the strata's total number of samples drawn
            sampled[strata_idx] = len(strata_samples)

            for idx in range(sampled[strata_idx]):
                sample = strata_samples[idx]
                matches_predicate = strata_samples_match_predicate[idx]

                # keep sample if it matches the predicate
                if matches_predicate:
                    samples[strata_idx].append(sample)
                    hits[strata_idx] += 1

        return samples, hits, sampled

    def get_strata(self, proxy_pred: float) -> int:
        """
        Return the index of the strata for the given proxy value.
        """
        for idx, upper_bound in enumerate(self.strata):
            if proxy_pred <= upper_bound:
                return idx

    def reservoir_sampling(self, strata_idx, oracle_pred, oracle_matches_predicate, warmup, frame):
        """
        Perform reservoir sampling within the specified strata for
        the given frame in the query.
        """
        # handle warmup sampling case first
        if warmup:   
            # get the strata's prior sample budget
            strata_budget = self.prior_samples_per_strata[strata_idx]

            # if reservoir isn't filled yet then add this frame to samples
            if len(self.warmup_samples[strata_idx]) < strata_budget:
                self.warmup_samples[strata_idx].append(oracle_pred)
                self.warmup_samples_match_predicate[strata_idx].append(oracle_matches_predicate)

            # otherwise apply reservoir sampling logic
            else:
                sample_prob = strata_budget / self.counts[strata_idx]
                if random.random() < sample_prob:
                    reservoir_idx = random.randint(0, strata_budget - 1)
                    self.warmup_samples[strata_idx][reservoir_idx] = oracle_pred
                    self.warmup_samples_match_predicate[strata_idx][reservoir_idx] = oracle_matches_predicate

        # handle dynamic sampling case
        else:
            # update dynamic sample allocation
            self.compute_pos_rates()
            self.compute_means_and_stds()
            self.compute_dynamic_samples_per_strata()

            # compute probability of sampling this sample; this is equal to the 
            # remaining sample budget for this strata divided by the expected
            # number of samples left in the stream for this strata, or the specified
            # minimum probability of sampling a frame
            expected_samples_left = (self.counts[strata_idx] / sum(self.counts)) * (self.end_frame - frame)
            sample_prob = max(self.min_dynamic_sample_prob, self.dynamic_samples_per_strata[strata_idx] / expected_samples_left)
            if random.random() < sample_prob:
                self.dynamic_samples[strata_idx].append(oracle_pred)
                self.dynamic_samples_match_predicate[strata_idx].append(oracle_matches_predicate)

    # def sample(self, proxy_pred, proxy_pred_to_prob, oracle_pred, oracle_matches_predicate):
    def sample(self, proxy_val, oracle_pred, oracle_matches_predicate, frame):
        """
        Update internal logic of the sampling class and return a prediction.
        """
        # get strata for sample based on proxy
        strata_idx = self.get_strata(proxy_val)

        # keep track of number of samples from each strata
        self.counts[strata_idx] += 1

        # do warm-up sampling or dynamic sampling depending on frame
        warmup = frame < self.warm_up_end_frame

        # make call to reservoir sampling
        self.reservoir_sampling(strata_idx, oracle_pred, oracle_matches_predicate, warmup, frame)

        # # compute dynamic sample budget per strata
        # self.compute_dynamic_samples_per_strata()

        # get strata based on proxy value and compute whether there are dynamic or prior samples left
        # strata_idx = self.get_strata(proxy_pred_to_prob[proxy_pred])
        # strata_idx = self.get_strata(proxy_val)
        # dynamic_samples_left = self.dynamic_samples_per_strata[strata_idx] > 0
        # prior_samples_left = self.prior_samples_per_strata[strata_idx] > 0

        # self.reservoir_sampling(strata_idx, oracle_pred, oracle_matches_predicate)

        # # TODO: change to probabilistic reservoir sampling approach
        # # if we have samples left for this strata, then sample the oracle
        # if dynamic_samples_left or prior_samples_left:
        #     self.sampled[strata_idx] += 1

        #     # use up prior sample budget before dipping into dynamic sample budget
        #     if prior_samples_left:
        #         self.prior_samples_per_strata[strata_idx] -= 1
        #     else:
        #         self.dynamic_budget -= 1

        #     # if oracle matches the predicate:
        #     # - increment hits
        #     # - add statistic to strata
        #     # - update computation of strata means and stds 
        #     if oracle_matches_predicate:
        #         self.hits[strata_idx] += 1
        #         self.samples[strata_idx].append(oracle_pred)
        #         self.compute_means_and_stds()

        # # recompute positive rate(s)
        # self.compute_pos_rates()

class StaticSampling(BaseSampling):
    """
    Static stratified sampling baseline.
    """

    def __init__(
        self,
        num_strata: int,
        num_segments: int,
        query: QueryType,
    ):
        """
        Initialize state needed to do basic sampling.
        """
        self.num_strata = num_strata
        self.budget = query.oracle_limit
        self.query = query
        self.num_segments = num_segments

        # set budget per segment
        self.segment_budgets = [
            round((1/(self.num_segments)) * self.budget)
            for segment_idx in range(self.num_segments)
        ]

        # add back any rounded off samples
        idx = 0
        while sum(self.segment_budgets) < self.budget:
            self.segment_budgets[idx] += 1
            idx = (idx + 1) % self.num_segments

        # determine the end frame for each segment
        self.segment_end_frames = []
        for idx in range(self.num_segments):
            end_frame = (
                round(((idx + 1)/self.num_segments) * query.end_frame)
                if idx < self.num_segments - 1
                else query.end_frame + 1
            )
            self.segment_end_frames.append(end_frame)
 
        # initialize counts
        self.counts = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]

        # initialize dynamic strata budgets
        self.samples_per_strata = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]

        # evenly distribute samples for all segments
        for segment_idx in range(0, self.num_segments):
            num_strata_samples = int(np.floor(self.segment_budgets[segment_idx]/self.num_strata))
            for strata_idx in range(self.num_strata):
                self.samples_per_strata[segment_idx][strata_idx] = num_strata_samples
        
            # add back any rounded off samples
            idx = 0
            while sum(self.samples_per_strata[segment_idx]) < self.segment_budgets[segment_idx]:
                self.samples_per_strata[segment_idx][idx] += 1
                idx = (idx + 1) % self.num_strata

        # list of samples per strata
        self.samples = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        self.samples_match_predicate = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        self.sample_frames = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]

        # TODO: remove
        self._pos_rates = []
        self._stds = []
        self._weights = []

        # the strata for the current segment
        self.strata = [0.3333, 0.6667, 1.0001]

    def compute_prediction(self, trial_idx):
        """
        Return the predicted answer(s) to the given query.
        """
        samples_by_segment = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        hits_by_segment = [
            [0 for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        sampled_by_segment = [
            [0 for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]

        for segment in range(self.num_segments):
            for strata_idx in range(self.num_strata):
                samples_ = self.samples[segment][strata_idx]
                samples_match_predicate_ = self.samples_match_predicate[segment][strata_idx]
                sampled_by_segment[segment][strata_idx] = len(samples_)

                for sample, matches_predicate in zip(samples_, samples_match_predicate_):
                    if matches_predicate:
                        samples_by_segment[segment][strata_idx].append(sample) # .append(int(sample))
                        hits_by_segment[segment][strata_idx] += 1

        # with open(f'results/samples-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(samples_by_segment, f)

        # with open(f'results/hits-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(hits_by_segment, f)

        # with open(f'results/sampled-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(sampled_by_segment, f)
        
        # with open(f'results/raw-dynamic-allocs-{trial_idx}.json', 'w') as f:
        #     json.dump(self.raw_dynamic_allocations, f)
        
        # ###############
        # with open(f'results/raw-pos-rates-{trial_idx}.json', 'w') as f:
        #     json.dump(self._pos_rates, f)
        
        # with open(f'results/raw-stds-{trial_idx}.json', 'w') as f:
        #     json.dump(self._stds, f)
        
        # with open(f'results/raw-weights-{trial_idx}.json', 'w') as f:
        #     json.dump(self._weights, f)
        # ###############

        # with open(f'results/sample-allocations-{trial_idx}.json', 'w') as f:
        #     json.dump(self.samples_per_strata, f)

        # with open(f'results/strata-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(self.computed_strata, f)

        # with open(f'results/sample-frames-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(self.sample_frames, f)

        # with open(f'results/sample-matches-predicate-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(self.samples_match_predicate, f)

        my_means = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]
        my_counts = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]
        for segment in range(self.num_segments):
            for strata_idx in range(self.num_strata):
                mean = np.mean(samples_by_segment[segment][strata_idx]) if len(samples_by_segment[segment][strata_idx]) > 0 else 0
                pos_rate = (
                    hits_by_segment[segment][strata_idx] / sampled_by_segment[segment][strata_idx]
                    if sampled_by_segment[segment][strata_idx] > 0
                    else 0
                )
                count = self.counts[segment][strata_idx] * pos_rate
                my_means[segment][strata_idx] = mean
                my_counts[segment][strata_idx] = count

        # with open(f'results/means-{trial_idx}.json', 'w') as f:
        #     json.dump(my_means, f)

        # with open(f'results/counts-{trial_idx}.json', 'w') as f:
        #     json.dump(my_counts, f)

        total_counts = np.sum(np.array(my_counts))
        prediction = 0
        for segment in range(self.num_segments):
            for strata_idx in range(self.num_strata):
                if total_counts > 0:
                    prediction += my_means[segment][strata_idx] * (my_counts[segment][strata_idx]/total_counts)

        return prediction

    def get_strata(self, proxy_pred: float) -> int:
        """
        Return the index of the strata for the given proxy value.
        """
        for idx, upper_bound in enumerate(self.strata):
            if proxy_pred < upper_bound:
                return idx

        raise Exception(f"didn't find strata idx for {proxy_pred} and {self.strata}")

    def sampling(self, strata_idx, oracle_pred, oracle_matches_predicate, segment, frame):
        """
        Perform sampling within the specified strata for the given frame in the query.
        """
        # get the strata's sample budget
        strata_budget = int(self.samples_per_strata[segment][strata_idx])

        # if reservoir isn't filled yet then add this frame to samples
        if len(self.samples[segment][strata_idx]) < strata_budget:
            self.samples[segment][strata_idx].append(oracle_pred)
            self.samples_match_predicate[segment][strata_idx].append(oracle_matches_predicate)
            self.sample_frames[segment][strata_idx].append(frame)

        # otherwise apply reservoir sampling logic
        else:
            sample_prob = strata_budget / self.counts[segment][strata_idx]
            if random.random() < sample_prob:
                reservoir_idx = random.randint(0, strata_budget - 1)
                self.samples[segment][strata_idx][reservoir_idx] = oracle_pred
                self.samples_match_predicate[segment][strata_idx][reservoir_idx] = oracle_matches_predicate
                self.sample_frames[segment][strata_idx][reservoir_idx] = frame

    def sample(self, proxy_val, oracle_pred, oracle_matches_predicate, frame):
        """
        Update internal logic of the sampling class and return a prediction.
        """
        # get segment depending on frame
        segment = None
        for segment_idx in range(self.num_segments):
            if frame < self.segment_end_frames[segment_idx]:
                segment = segment_idx
                break

        # get strata for sample based on proxy
        strata_idx = self.get_strata(proxy_val)

        # update counts depending on segment
        self.counts[segment][strata_idx] += 1

        # make call to reservoir sampling
        self.sampling(strata_idx, oracle_pred, oracle_matches_predicate, segment, frame)


class DynamicSampling(BaseSampling):
    """
    A basic sampling approach that uses a warm-up phase followed by sampling according
    to the estimated optimal sampling allocation.
    """

    def __init__(
        self,
        num_strata: int,
        num_segments: int,
        query: QueryType,
        defensive: bool=False,
        defensive_frac: float=0.1,
        pilot_sample_frac: float=0.1,
        pilot_query_frac: float=0.1,
        strata_ewm_alpha: float=0.8,
        alloc_ewm_alpha: float=0.8,
        min_strata_gap: float=None,
        subsample: int=None,
        strata_epsilon: float=1e-6,
        fix_strata: bool=False,
        fix_alloc: bool=False,
    ):
        """
        Initialize state needed to do basic sampling.
        """
        self.num_strata = num_strata
        self.budget = query.oracle_limit
        self.query = query
        self.num_segments = num_segments
        self.defensive = defensive
        self.defensive_frac = defensive_frac
        self.pilot_sample_frac = pilot_sample_frac
        self.pilot_query_frac = pilot_query_frac
        self.strata_ewm_alpha = strata_ewm_alpha
        self.alloc_ewm_alpha = alloc_ewm_alpha
        self.min_strata_gap = min_strata_gap
        self.subsample = subsample
        self.strata_epsilon=strata_epsilon
        self.fix_strata = fix_strata
        self.fix_alloc = fix_alloc

        # determine pilot budget and update budget
        self.pilot_budget = int(np.floor(self.budget * self.pilot_sample_frac))
        self.budget -= self.pilot_budget

        # compute pilot end_frame
        self.pilot_end_frame = query.start_frame + int(np.floor((query.end_frame - query.start_frame) * self.pilot_query_frac))

        # set budget per segment
        self.segment_budgets = [
            self.pilot_budget
            if segment_idx == 0
            else round((1/(self.num_segments - 1)) * self.budget)
            for segment_idx in range(self.num_segments)
        ]

        # add back any rounded off samples
        idx = 0
        while sum(self.segment_budgets) < self.budget:
            self.segment_budgets[idx] += 1
            idx = (idx + 1) % self.num_segments

        # determine the end frame for each segment
        self.segment_end_frames = []
        for idx in range(self.num_segments):
            # if we're pilot sampling
            if idx == 0:
                self.segment_end_frames.append(self.pilot_end_frame)
            else:
                end_frame = (
                    self.pilot_end_frame + round((idx/(self.num_segments - 1)) * (query.end_frame - self.pilot_end_frame))
                    if idx < self.num_segments - 1
                    else query.end_frame + 1
                )
                self.segment_end_frames.append(end_frame)
 

        self.dynamic_computed = [False for _ in range(self.num_segments)]
        self.strata_computed = [False for _ in range(self.num_segments)]

        # initialize counts
        self.counts = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]

        # initialize dynamic strata budgets
        self.samples_per_strata = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]

        # for lesion study, if we fix allocations evenly distribute samples for all segments (pilot will still use uniform)
        if self.fix_alloc:
            for segment_idx in range(1, self.num_segments):
                num_strata_samples = int(np.floor(self.segment_budgets[segment_idx]/self.num_strata))
                for strata_idx in range(self.num_strata):
                    self.samples_per_strata[segment_idx][strata_idx] = num_strata_samples
            
                # add back any rounded off samples
                idx = 0
                while sum(self.samples_per_strata[segment_idx]) < self.segment_budgets[segment_idx]:
                    self.samples_per_strata[segment_idx][idx] += 1
                    idx = (idx + 1) % self.num_strata

        # select frames to sample during uniform sampling
        frames = np.arange(0, self.pilot_end_frame, self.subsample)
        self.pilot_uniform_frames_to_sample = set(np.random.choice(
            frames,
            size=min(self.segment_budgets[0], len(frames)),
            replace=False,
        ))

        # list to store pilot samples
        self.pilot_samples = []

        # list of samples per strata
        self.samples = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        self.samples_match_predicate = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        self.sample_frames = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]

        # keep track of proxy values that evenly divide each segment into strata
        self.segment_to_dividing_proxy_vals = []

        # keep track of raw allocations based on samples
        self.raw_dynamic_allocations = []

        # TODO: remove
        self._pos_rates = []
        self._stds = []
        self._weights = []

        # keep track of mapping from frame to proxy value for all proxy values to compute optimal strata
        self.all_proxy_values = []

        # the strata for the current segment
        self.strata = None

        # for lesion study we may choose to fix the strata
        if self.fix_strata:
            self.strata = [0.3333, 0.6667, 1.0001]

        # keep track of strata computations
        self.computed_strata = []

    def compute_prediction(self, trial_idx):
        """
        Return the predicted answer(s) to the given query.
        """
        samples_by_segment = [
            [[] for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        hits_by_segment = [
            [0 for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]
        sampled_by_segment = [
            [0 for _ in range(self.num_strata)]
            for _ in range(self.num_segments)
        ]

        for segment in range(self.num_segments):
            for strata_idx in range(self.num_strata):
                samples_ = self.samples[segment][strata_idx]
                samples_match_predicate_ = self.samples_match_predicate[segment][strata_idx]
                sampled_by_segment[segment][strata_idx] = len(samples_)

                for sample, matches_predicate in zip(samples_, samples_match_predicate_):
                    if matches_predicate:
                        samples_by_segment[segment][strata_idx].append(sample) # .append(int(sample))
                        hits_by_segment[segment][strata_idx] += 1

        # with open(f'results/samples-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(samples_by_segment, f)

        # with open(f'results/hits-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(hits_by_segment, f)

        # with open(f'results/sampled-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(sampled_by_segment, f)
        
        # with open(f'results/raw-dynamic-allocs-{trial_idx}.json', 'w') as f:
        #     json.dump(self.raw_dynamic_allocations, f)
        
        # ###############
        # with open(f'results/raw-pos-rates-{trial_idx}.json', 'w') as f:
        #     json.dump(self._pos_rates, f)
        
        # with open(f'results/raw-stds-{trial_idx}.json', 'w') as f:
        #     json.dump(self._stds, f)
        
        # with open(f'results/raw-weights-{trial_idx}.json', 'w') as f:
        #     json.dump(self._weights, f)
        # ###############

        # with open(f'results/sample-allocations-{trial_idx}.json', 'w') as f:
        #     json.dump(self.samples_per_strata, f)

        # with open(f'results/strata-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(self.computed_strata, f)

        # with open(f'results/sample-frames-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(self.sample_frames, f)

        # with open(f'results/sample-matches-predicate-by-segment-{trial_idx}.json', 'w') as f:
        #     json.dump(self.samples_match_predicate, f)

        my_means = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]
        my_counts = [[0 for _ in range(self.num_strata)] for _ in range(self.num_segments)]
        for segment in range(self.num_segments):
            for strata_idx in range(self.num_strata):
                mean = np.mean(samples_by_segment[segment][strata_idx]) if len(samples_by_segment[segment][strata_idx]) > 0 else 0
                pos_rate = (
                    hits_by_segment[segment][strata_idx] / sampled_by_segment[segment][strata_idx]
                    if sampled_by_segment[segment][strata_idx] > 0
                    else 0
                )
                count = self.counts[segment][strata_idx] * pos_rate
                my_means[segment][strata_idx] = mean
                my_counts[segment][strata_idx] = count

        # with open(f'results/means-{trial_idx}.json', 'w') as f:
        #     json.dump(my_means, f)

        # with open(f'results/counts-{trial_idx}.json', 'w') as f:
        #     json.dump(my_counts, f)

        total_counts = np.sum(np.array(my_counts))
        prediction = 0
        for segment in range(self.num_segments):
            for strata_idx in range(self.num_strata):
                if total_counts > 0:
                    prediction += my_means[segment][strata_idx] * (my_counts[segment][strata_idx]/total_counts)

        return prediction

    def compute_strata(self, segment):
        # no computation needed for lesion study -- other than populating counts after pilot
        if self.fix_strata:
            self.computed_strata.append(self.strata)

            if segment == 1:
                proxy_df = pd.DataFrame(self.all_proxy_values)
                for oracle_pred, oracle_matches_predicate, frame in self.pilot_samples:
                    proxy_val = proxy_df[proxy_df.frame == frame]['proxy'].iloc[0]
                    strata = self.get_strata(proxy_val)

                    # update relevant state
                    self.samples[0][strata].append(oracle_pred)
                    self.samples_match_predicate[0][strata].append(oracle_matches_predicate)
                    self.sample_frames[0][strata].append(frame)

                frames = np.arange(0, self.pilot_end_frame, self.subsample)
                for frame in frames:
                    proxy_val = proxy_df[proxy_df.frame == frame]['proxy'].iloc[0]
                    strata = self.get_strata(proxy_val)
                    self.counts[0][strata] += 1

            return

        # # determine whether we have a predicate or not
        # no_predicate = (self.query.predicate == "")

        # create dataframe of proxy values so far; each row has (frame, proxy)
        proxy_df = pd.DataFrame(self.all_proxy_values)

        # for previous segment, find evenly dividing proxy values
        # identify subset of proxy values within segment
        prev_segment = segment - 1
        segment_start_frame = self.segment_end_frames[prev_segment - 1] if prev_segment > 0 else 0
        segment_end_frame = self.segment_end_frames[prev_segment]
        segment_proxy_df = proxy_df[
            (segment_start_frame <= proxy_df.frame)
            & (proxy_df.frame < segment_end_frame)
        ]

        # # filter for predicate matching sampled frames
        # sampled_frames = list(np.array(self.sample_frames).flatten())
        # pred_segment_proxy_df = full_segment_proxy_df[
        #     full_segment_proxy_df.frame.isin(sampled_frames)
        #     & full_segment_proxy_df.matches_pred
        # ]

        # compute strata using .quantile() on proxy values
        strata = [0 for _ in range(self.num_strata)]
        for strata_idx in range(self.num_strata):
            # normal case
            # if len(pred_segment_proxy_df.proxy.unique()) > 2:
            quantile = (strata_idx + 1)/self.num_strata
            strata[strata_idx] = (
                segment_proxy_df.proxy.quantile(quantile)
                if strata_idx < self.num_strata - 1
                else 1.0001
            )

            # # in case where we don't have many pred matching samples, use proxies instead
            # else:
            #     print("Warning: fewer than 3 predicate matching samples in previous segment")
            #     min_proxy = full_segment_proxy_df.proxy.min()
            #     max_proxy = full_segment_proxy_df.proxy.max()
            #     strata[strata_idx] = min_proxy + ((strata_idx + 1) / self.num_strata) * (max_proxy - min_proxy)

        # add evenly dividing strata to segment_to_dividing_proxy_vals
        self.segment_to_dividing_proxy_vals.append(strata)

        # compute upcoming segment's strata using weighted moving average
        dividing_proxy_df = pd.DataFrame(self.segment_to_dividing_proxy_vals)
        self.strata = dividing_proxy_df.ewm(alpha=self.strata_ewm_alpha).mean().iloc[-1].tolist()

        # add small epsilon to each strata upper bound; we do this because our splits
        # have a non-trivial likelihood of falling on values that the proxy will
        # frequently output; if we set that exact value to be the upper bound then
        # samples with that proxy value will not be included in the strata due to
        # the fact that we use lower_bound <= proxy < upper_bound to determine placement
        for strata_idx in range(self.num_strata):
            self.strata[strata_idx] += self.strata_epsilon

        # manually ensure that there's at least some min gap between strata values
        for strata_idx in range(self.num_strata - 1):
            # note: we use >= because it's possible that three consecutive
            # strata could have the same value, in which case if we bump
            # the second strata to be self.min_strata_gap more than the first,
            # this will be greater than the value for the third strata
            if self.strata[strata_idx] >= self.strata[strata_idx + 1]:
                self.strata[strata_idx + 1] = self.strata[strata_idx] + self.min_strata_gap

        # manually set last strata to have upper limit of 1.0001
        self.strata[self.num_strata - 1] = 1.0001

        # add finalized strata to list of computed strata
        self.computed_strata.append(self.strata)

        # if we just finished the pilot, compute self.counts using strata we just computed for segment == 1
        if segment == 1:
            proxy_df = pd.DataFrame(self.all_proxy_values)
            for oracle_pred, oracle_matches_predicate, frame in self.pilot_samples:
                proxy_val = proxy_df[proxy_df.frame == frame]['proxy'].iloc[0]
                strata = self.get_strata(proxy_val)

                # update relevant state
                self.samples[0][strata].append(oracle_pred)
                self.samples_match_predicate[0][strata].append(oracle_matches_predicate)
                self.sample_frames[0][strata].append(frame)

            frames = np.arange(0, self.pilot_end_frame, self.subsample)
            for frame in frames:
                proxy_val = proxy_df[proxy_df.frame == frame]['proxy'].iloc[0]
                strata = self.get_strata(proxy_val)
                self.counts[0][strata] += 1

    def get_strata(self, proxy_pred: float) -> int:
        """
        Return the index of the strata for the given proxy value.
        """
        for idx, upper_bound in enumerate(self.strata):
            if proxy_pred < upper_bound:
                return idx

        raise Exception(f"didn't find strata idx for {proxy_pred} and {self.strata}")

    def compute_dynamic_sample_allocation(self, segment):
        """
        Compute allocation for dynamic samples across strata.
        """
        samples_by_segment = [
            [[] for _ in range(self.num_strata)]
            for _ in range(segment)
        ]
        hits_by_segment = [
            [0 for _ in range(self.num_strata)]
            for _ in range(segment)
        ]
        sampled_by_segment = [
            [0 for _ in range(self.num_strata)]
            for _ in range(segment)
        ]
        for segment_idx in range(segment):
            for strata_idx in range(self.num_strata):
                samples_ = self.samples[segment_idx][strata_idx]
                samples_match_predicate_ = self.samples_match_predicate[segment_idx][strata_idx]
                sampled_by_segment[segment_idx][strata_idx] = len(samples_)

                for sample, matches_predicate in zip(samples_, samples_match_predicate_):
                    if matches_predicate:
                        samples_by_segment[segment_idx][strata_idx].append(int(sample))
                        hits_by_segment[segment_idx][strata_idx] += 1

        # start computing raw allocation based on samples from previous segment
        prev_segment = segment - 1

        # compute strata pos. rate
        pos_rate_per_strata = [
            hits_by_segment[prev_segment][strata_idx] / sampled_by_segment[prev_segment][strata_idx] if sampled_by_segment[prev_segment][strata_idx] > 0 else 0
            for strata_idx in range(self.num_strata)
        ]

        means, stds = [0 for _ in range(self.num_strata)], [0 for _ in range(self.num_strata)]
        for strata_idx in range(self.num_strata):
            means[strata_idx] = (
                np.mean(samples_by_segment[prev_segment][strata_idx])
                if len(samples_by_segment[prev_segment][strata_idx]) > 0
                else 0
            )

            stds[strata_idx] = (
                np.std(samples_by_segment[prev_segment][strata_idx], ddof=1)
                if len(samples_by_segment[prev_segment][strata_idx]) > 1
                else 0
            )
    
        # compute strata weights and total weight
        strata_weights = [
            np.sqrt(pos_rate_per_strata[strata_idx] * (self.counts[prev_segment][strata_idx]/np.sum(self.counts[prev_segment]))) * stds[strata_idx]
            for strata_idx in range(self.num_strata)
        ]

        total_weight = np.sum(strata_weights)

        self._pos_rates.append(list(pos_rate_per_strata))
        self._stds.append(list(stds))
        self._weights.append(list(self.counts[prev_segment]/np.sum(self.counts[prev_segment])))

        # compute allocs
        raw_allocs = (
            [strata_weight / total_weight for strata_weight in strata_weights]
            if total_weight > 0
            else [1 / self.num_strata for _ in strata_weights]
        )
        self.raw_dynamic_allocations.append(raw_allocs)

        # compute upcoming segment's dynamic alloc using weighted moving average
        raw_alloc_df = pd.DataFrame(self.raw_dynamic_allocations)
        allocs = raw_alloc_df.ewm(alpha=self.alloc_ewm_alpha).mean().iloc[-1].tolist()

        # compute defensive set of samples
        strata_defensive_samples = 0
        if self.defensive:
            strata_defensive_samples = np.floor((self.segment_budgets[segment] * self.defensive_frac) / self.num_strata)

        # compute dynamic segment budget accounting for defensive samples
        segment_budget = self.segment_budgets[segment]
        if self.defensive:
            segment_budget = np.floor(self.segment_budgets[segment] * (1 - self.defensive_frac))

        # compute dynamic samples per strata
        self.samples_per_strata[segment] = [
            np.floor(strata_defensive_samples + segment_budget * allocs[strata_idx])
            for strata_idx in range(self.num_strata)
        ]
        # if total_weight > 0:
        #     self.samples_per_strata[segment] = [
        #         np.floor(strata_defensive_samples + segment_budget * allocs[strata_idx])
        #         for strata_idx in range(self.num_strata)
        #     ]
        # else:
        #     self.samples_per_strata[segment] = [self.segment_budgets[segment] / self.num_strata for _ in range(self.num_strata)]

        # add back floored out samples; use original segment budget for this
        if sum(self.samples_per_strata[segment]) < self.segment_budgets[segment]:
            num_samples = int(self.segment_budgets[segment] - sum(self.samples_per_strata[segment]))
            while num_samples > self.num_strata:
                for strata_idx in range(self.num_strata):
                    self.samples_per_strata[segment][strata_idx] += 1
                num_samples = int(self.segment_budgets[segment] - sum(self.samples_per_strata[segment]))

            indices = np.random.choice(np.arange(self.num_strata), size=num_samples, replace=False)

            for strata_idx in indices:
                self.samples_per_strata[segment][strata_idx] += 1

    def sampling(self, strata_idx, oracle_pred, oracle_matches_predicate, segment, frame):
        """
        Perform sampling within the specified strata for the given frame in the query.
        """
        # if we're in the pilot, perform uniform sampling
        if segment == 0:
            if frame in self.pilot_uniform_frames_to_sample:
                self.pilot_samples.append((oracle_pred, oracle_matches_predicate, frame))

            return

        # compute dynamic sampling allocation if we haven't yet
        if segment > 0 and not self.dynamic_computed[segment] and not self.fix_alloc:  # second condition ensures we do this once
            self.compute_dynamic_sample_allocation(segment)
            self.dynamic_computed[segment] = True

        # get the strata's dynamic sample budget
        strata_budget = int(self.samples_per_strata[segment][strata_idx])

        # if reservoir isn't filled yet then add this frame to samples
        if len(self.samples[segment][strata_idx]) < strata_budget:
            self.samples[segment][strata_idx].append(oracle_pred)
            self.samples_match_predicate[segment][strata_idx].append(oracle_matches_predicate)
            self.sample_frames[segment][strata_idx].append(frame)

        # otherwise apply reservoir sampling logic
        else:
            sample_prob = strata_budget / self.counts[segment][strata_idx]
            if random.random() < sample_prob:
                reservoir_idx = random.randint(0, strata_budget - 1)
                self.samples[segment][strata_idx][reservoir_idx] = oracle_pred
                self.samples_match_predicate[segment][strata_idx][reservoir_idx] = oracle_matches_predicate
                self.sample_frames[segment][strata_idx][reservoir_idx] = frame

    def sample(self, proxy_val, oracle_pred, oracle_matches_predicate, frame):
        """
        Update internal logic of the sampling class and return a prediction.
        """
        # get segment depending on frame
        segment = None
        for segment_idx in range(self.num_segments):
            if frame < self.segment_end_frames[segment_idx]:
                segment = segment_idx
                break

        # compute strata for segment if they haven't been computed already
        if segment > 0 and not self.strata_computed[segment]:
            self.compute_strata(segment)
            self.strata_computed[segment] = True

        # get strata_idx
        strata_idx = None
        if segment > 0:
            # get strata for sample based on proxy
            strata_idx = self.get_strata(proxy_val)

            # update counts depending on segment
            self.counts[segment][strata_idx] += 1

        # make call to reservoir sampling
        self.sampling(strata_idx, oracle_pred, oracle_matches_predicate, segment, frame)

        # add proxy_val to list of all proxy values
        self.all_proxy_values.append({"frame": frame, "proxy": proxy_val, "count": oracle_pred, "matches_pred": oracle_matches_predicate})


class SimpleSamplingOld(BaseSampling):
    """
    A basic sampling approach that uses a warm-up phase followed by sampling according
    to the estimated optimal sampling allocation.
    """

    def __init__(
        self,
        strata: List[float],
        prior: List[float],
        query: QueryType,
        chunks: int,
        defensive: bool=False,
        defensive_frac: float=0.5,
        pilot: bool=False,
        pilot_sample_frac: float=0.02,
        pilot_query_frac: float=0.01,
        dynamic: bool=True,
        dynamic_allocation_use_all_chunks: bool=False,
        infer_strata: bool=False,
        min_strata_gap: float=None,
        subsample: int=None,
        strata_epsilon: float=1e-6,
    ):
        """
        Initialize state needed to do basic sampling.
        """
        self.S = len(strata)
        self.strata = sorted(strata)
        self.budget = query.oracle_limit
        self.query = query
        self.chunks = chunks
        self.defensive = defensive
        self.defensive_frac = defensive_frac
        self.pilot = pilot
        self.pilot_sample_frac = pilot_sample_frac
        self.pilot_query_frac = pilot_query_frac
        self.dynamic = dynamic
        self.dynamic_allocation_use_all_chunks = dynamic_allocation_use_all_chunks
        self.infer_strata = infer_strata
        self.min_strata_gap = min_strata_gap
        self.subsample = subsample
        self.strata_epsilon=strata_epsilon

        # if we're doing pilot sampling, treat this as adding an extra initial chunk
        if self.pilot:
            self.chunks += 1

            # determine pilot budget and update budget
            self.pilot_budget = int(np.floor(self.budget * self.pilot_sample_frac))
            self.budget -= self.pilot_budget

            # compute pilot end_frame
            self.pilot_end_frame = int(np.floor(query.end_frame * self.pilot_query_frac))

        # set budget per chunk
        self.chunk_budgets = (
            [
                self.pilot_budget
                if chunk_idx == 0
                else round((1/(self.chunks - 1)) * self.budget)
                for chunk_idx in range(self.chunks)
            ]
            if self.pilot
            else [round((1/self.chunks) * self.budget) for _ in range(self.chunks)]
        )

        # add back any rounded off samples
        idx = 0
        while sum(self.chunk_budgets) < self.budget:
            self.chunk_budgets[idx] += 1
            idx = (idx + 1) % self.chunks

        # determine the end frame for each chunk
        self.chunk_end_frames = []
        for idx in range(self.chunks):
            # if we're pilot sampling
            if self.pilot and idx == 0:
                self.chunk_end_frames.append(self.pilot_end_frame)
            elif self.pilot and idx > 0:
                end_frame = (
                    query.start_frame + round((idx/(self.chunks - 1)) * (query.end_frame - query.start_frame))
                    if idx < self.chunks - 1
                    else query.end_frame
                )
                self.chunk_end_frames.append(end_frame)
            
            # if we're not pilot sampling
            else:
                end_frame = (
                    query.start_frame + round(((idx + 1)/self.chunks) * (query.end_frame - query.start_frame))
                    if idx < self.chunks - 1
                    else query.end_frame
                )
                self.chunk_end_frames.append(end_frame)

        # self.chunk_end_frames = [
        #     (
        #         query.start_frame + round(((idx + 1)/chunks) * (query.end_frame - query.start_frame))
        #         if idx < chunks - 1
        #         else query.end_frame
        #     )
        #     for idx in range(self.chunks)
        # ]
        self.dynamic_computed = [False for _ in range(self.chunks)]
        self.strata_computed = [False for _ in range(self.chunks)]

        # initialize means and stds
        self.means = [0 for _ in range(self.S)]
        self.stds = [0 for _ in range(self.S)]

        # initialize counts
        self.counts = [[0 for _ in range(self.S)] for _ in range(self.chunks)]

        # initialize strata budgets
        if not self.infer_strata:
            self.samples_per_strata = [
                (
                    [int(np.floor(self.chunk_budgets[0] * strata_prior)) for strata_prior in prior]
                    if idx == 0
                    else None
                )
                for idx in range(self.chunks)
            ]

            # add back any samples that were rounded off
            idx = 0
            while sum(self.samples_per_strata[0]) < self.chunk_budgets[0]:
                self.samples_per_strata[0][idx] += 1
                idx = (idx + 1) % self.S

        else:
            # give all pilot budget to first chunk for uniform sampling
            self.samples_per_strata = [None for idx in range(self.chunks)]

            frames = np.arange(0, self.pilot_end_frame, self.subsample)
            self.pilot_uniform_frames_to_sample = set(np.random.choice(
                frames,
                size=min(self.chunk_budgets[0], len(frames)),
                replace=False,
            ))

            # keep track of mapping from frame to proxy value for all proxy values to compute optimal strata
            self.all_proxy_values = {}

            # list to store pilot samples
            self.pilot_samples = []

        # list of samples per strata
        self.samples = [
            [[] for _ in range(self.S)]
            for _ in range(self.chunks)
        ]
        self.samples_match_predicate = [
            [[] for _ in range(self.S)]
            for _ in range(self.chunks)
        ]
        self.sample_frames = [
            [[] for _ in range(self.S)]
            for _ in range(self.chunks)
        ]

        # keep track of strata computations
        self.all_strata = []

    def compute_prediction(self, trial_idx):
        """
        Return the predicted answer(s) to the given query.
        """
        # get final set of samples matching predicate
        samples, hits, sampled, samples_by_chunk, hits_by_chunk, sampled_by_chunk = self.get_samples(compute_prediction=True)

        # # compute strata pos. rate
        # pos_rate_per_strata = [
        #     hits[strata_idx] / sampled[strata_idx] if sampled[strata_idx] > 0 else 0
        #     for strata_idx in range(self.S)
        # ]

        with open(f'results/samples-by-chunk-{trial_idx}.json', 'w') as f:
            json.dump(samples_by_chunk, f)
        
        with open(f'results/hits-by-chunk-{trial_idx}.json', 'w') as f:
            json.dump(hits_by_chunk, f)

        with open(f'results/sampled-by-chunk-{trial_idx}.json', 'w') as f:
            json.dump(sampled_by_chunk, f)

        with open(f'results/sample-allocations-{trial_idx}.json', 'w') as f:
            json.dump(self.samples_per_strata, f)
        
        with open(f'results/strata-by-chunk-{trial_idx}.json', 'w') as f:
            json.dump(self.all_strata, f)

        with open(f'results/sample-frames-by-chunk-{trial_idx}.json', 'w') as f:
            json.dump(self.sample_frames, f)

        with open(f'results/sample-matches-predicate-by-chunk-{trial_idx}.json', 'w') as f:
            json.dump(self.samples_match_predicate, f)

        my_means = [[0 for _ in range(self.S)] for _ in range(self.chunks)]
        my_counts = [[0 for _ in range(self.S)] for _ in range(self.chunks)]
        for chunk in range(self.chunks):
            for strata_idx in range(self.S):
                mean = np.mean(samples_by_chunk[chunk][strata_idx]) if len(samples_by_chunk[chunk][strata_idx]) > 0 else 0
                pos_rate = (
                    hits_by_chunk[chunk][strata_idx] / sampled_by_chunk[chunk][strata_idx]  # TODO: how did this not error before?
                    if sampled_by_chunk[chunk][strata_idx] > 0
                    else 0
                )
                count = self.counts[chunk][strata_idx] * pos_rate
                my_means[chunk][strata_idx] = mean
                my_counts[chunk][strata_idx] = count

        with open(f'results/means-{trial_idx}.json', 'w') as f:
            json.dump(my_means, f)

        with open(f'results/counts-{trial_idx}.json', 'w') as f:
            json.dump(my_counts, f)

        total_counts = np.sum(np.array(my_counts))
        prediction = 0
        for chunk in range(self.chunks):
            for strata_idx in range(self.S):
                if total_counts > 0:
                    prediction += my_means[chunk][strata_idx] * (my_counts[chunk][strata_idx]/total_counts)

        return prediction

    def get_samples(self, chunk=None, compute_prediction=False):
        """
        Return the samples generated by the sampling strategy; filter for
        the samples that actually match the predicate.
        """
        # initialize return variables
        
        samples = [[] for _ in range(self.S)]
        hits = [0 for _ in range(self.S)]
        sampled = [0 for _ in range(self.S)]
        samples_by_chunk = [
            [[] for _ in range(self.S)]
            for _ in range(self.chunks)
        ]
        hits_by_chunk = [
            [0 for _ in range(self.S)]
            for _ in range(self.chunks)
        ]
        sampled_by_chunk = [
            [0 for _ in range(self.S)]
            for _ in range(self.chunks)
        ]

        # if chunk is None then collect data for all chunks
        num_chunks = chunk if chunk is not None else self.chunks

        for strata_idx in range(self.S):
            # collect strata samples
            strata_samples, strata_samples_match_predicate = [], []
            if self.dynamic_allocation_use_all_chunks or compute_prediction:
                for chunk in range(num_chunks):
                    strata_samples.extend(self.samples[chunk][strata_idx])
                    strata_samples_match_predicate.extend(self.samples_match_predicate[chunk][strata_idx])
            else:
                strata_samples.extend(self.samples[chunk - 1][strata_idx])
                strata_samples_match_predicate.extend(self.samples_match_predicate[chunk - 1][strata_idx])

            # get the strata's total number of samples drawn
            sampled[strata_idx] = len(strata_samples)

            for idx in range(sampled[strata_idx]):
                sample = strata_samples[idx]
                matches_predicate = strata_samples_match_predicate[idx]

                # keep sample if it matches the predicate
                if matches_predicate:
                    samples[strata_idx].append(sample)
                    hits[strata_idx] += 1
        
        for chunk in range(self.chunks):
            for strata_idx in range(self.S):
                samples_ = self.samples[chunk][strata_idx]
                samples_match_predicate_ = self.samples_match_predicate[chunk][strata_idx]
                sampled_by_chunk[chunk][strata_idx] = len(samples_)

                for sample, matches_predicate in zip(samples_, samples_match_predicate_):
                    if matches_predicate:
                        samples_by_chunk[chunk][strata_idx].append(int(sample))
                        hits_by_chunk[chunk][strata_idx] += 1

        return samples, hits, sampled, samples_by_chunk, hits_by_chunk, sampled_by_chunk

    def get_strata(self, proxy_pred: float, chunk: int, no_compute=False) -> int:
        """
        Return the index of the strata for the given proxy value.
        """
        # hacky fix to ensure this runs once at start of each new chunk; self.dynamic_computed will be updated inside sampling
        if self.infer_strata and not no_compute:
            if chunk > 0 and not self.strata_computed[chunk]:  # condition ensures we do this once
                self.compute_strata(chunk == 1)
                self.strata_computed[chunk] = True

        for idx, upper_bound in enumerate(self.strata):
            if proxy_pred < upper_bound:
                return idx

        raise Exception(f"didn't find strata idx for {proxy_pred} and {self.strata}")

    def compute_dynamic_sample_allocation(self, chunk):
        """
        Compute allocation for dynamic samples across strata based on warmup stats.
        """
        # get samples matching predicate
        # samples, hits, sampled, _, _, _ = self.get_samples(chunk)
        _, _, _, samples_by_chunk, hits_by_chunk, sampled_by_chunk = self.get_samples(chunk)
        samples, hits, sampled, = samples_by_chunk[chunk - 1], hits_by_chunk[chunk - 1], sampled_by_chunk[chunk - 1]

        # compute strata pos. rate
        pos_rate_per_strata = [
            hits[strata_idx] / sampled[strata_idx] if sampled[strata_idx] > 0 else 0
            for strata_idx in range(self.S)
        ]

        for strata_idx in range(self.S):
            self.means[strata_idx] = (
                np.mean(samples[strata_idx])
                if len(samples[strata_idx]) > 0
                else 0
            )

            self.stds[strata_idx] = (
                np.std(samples[strata_idx], ddof=1)
                if len(samples[strata_idx]) > 1
                else 0
            )
        
        # compute strata weights and total weight
        strata_weights = [
            np.sqrt(pos_rate_per_strata[strata_idx]) * self.stds[strata_idx] * (self.counts[chunk-1][strata_idx]/np.sum(self.counts[chunk-1]))
            for strata_idx in range(self.S)
        ]

        total_weight = np.sum(strata_weights)

        # compute defensive set of samples
        strata_defensive_samples = 0
        if self.defensive:
            strata_defensive_samples = np.floor((self.chunk_budgets[chunk] * self.defensive_frac) / self.S)

        # compute chunk budget accounting for defensive samples
        chunk_budget = self.chunk_budgets[chunk]
        if self.defensive:
            chunk_budget = np.floor(self.chunk_budgets[chunk] * (1 - self.defensive_frac))

        # compute dynamic samples per strata
        if total_weight > 0:
            self.samples_per_strata[chunk] = [
                np.floor(strata_defensive_samples + chunk_budget * (strata_weights[strata_idx]/total_weight))
                for strata_idx in range(self.S)
            ]
        else:
            self.samples_per_strata[chunk] = [self.chunk_budgets[chunk] / self.S for _ in range(self.S)]

        # add back floored out samples; use original chunk budget for this
        if sum(self.samples_per_strata[chunk]) < self.chunk_budgets[chunk]:
            num_samples = int(self.chunk_budgets[chunk] - sum(self.samples_per_strata[chunk]))
            while num_samples > self.S:
                for strata_idx in range(self.S):
                    self.samples_per_strata[chunk][strata_idx] += 1
                num_samples = int(self.chunk_budgets[chunk] - sum(self.samples_per_strata[chunk]))

            indices = np.random.choice(np.arange(self.S), size=num_samples, replace=False)

            for strata_idx in indices:
                self.samples_per_strata[chunk][strata_idx] += 1

    def compute_strata(self, fst_chunk_after_pilot):
        # determine whether we have a predicate or not
        no_predicate = (self.query.predicate == "")

        # get proxy values for predicate matching samples sorted in ascending order
        sorted_proxy_values, frame_proxy_df, predicate_matching_frames = None, None, None
        if no_predicate:
            sorted_proxy_values = sorted(list(self.all_proxy_values.values()))

        elif fst_chunk_after_pilot:
            predicate_matching_sample_tuples = list(filter(lambda tup: tup[1], self.pilot_samples))
            predicate_matching_frames = list(map(lambda tup: tup[2], predicate_matching_sample_tuples))
            predicate_matching_proxy_values = list(map(lambda frame: self.all_proxy_values[frame], predicate_matching_frames))
            sorted_proxy_values = sorted(predicate_matching_proxy_values)

        else:
            # get sampled frames with predicate matching samples
            predicate_matching_frames = []
            all_frames, all_proxy_vals, all_sample_vals, all_match_vals = [], [], [], []
            for chunk in range(len(self.samples)):
                for strata in range(self.S):
                    for frame, sample, sample_matches_predicate in zip(self.sample_frames[chunk][strata], self.samples[chunk][strata], self.samples_match_predicate[chunk][strata]):
                        all_frames.append(frame)
                        all_proxy_vals.append(self.all_proxy_values[frame])
                        all_sample_vals.append(sample)
                        all_match_vals.append(sample_matches_predicate)
                        if sample_matches_predicate:
                            predicate_matching_frames.append(frame)

            # get proxy values for samples that match predicate
            frame_proxy_df = pd.DataFrame({"frame": all_frames, "proxy": all_proxy_vals, "sample_val": all_sample_vals, "match": all_match_vals})

            predicate_matching_df = frame_proxy_df[frame_proxy_df.frame.isin(predicate_matching_frames)]
            predicate_matching_proxy_values = predicate_matching_df.proxy.tolist()

            sorted_proxy_values = sorted(predicate_matching_proxy_values)

        split_indices, best_strata = None, None
        if no_predicate:
            # slightly hacky solution to reverse (start, stop) and use endpoint to get upper bounded endpoints
            split_indices = np.linspace(len(sorted_proxy_values), 0, self.S, endpoint=False, dtype=int)[::-1]
        else:
            # slightly hacky solution to reverse (start, stop) and use endpoint to get upper bounded endpoints
            split_indices = np.linspace(len(sorted_proxy_values), 0, self.S, endpoint=False, dtype=int)[::-1]
            # def compute_split_val(strata, frame_proxy_df, predicate_matching_frames):
            #     # split_val = 0
            #     split_vals = []
            #     for strata_idx in range(len(strata)):
            #         # get lower and upper limits on proxy values for strata
            #         lower = 0 if strata_idx == 0 else strata[strata_idx - 1]
            #         upper = strata[strata_idx]
                    
            #         strata_df = frame_proxy_df[(lower <= frame_proxy_df.proxy) & (frame_proxy_df.proxy < upper)]
            #         strata_pred_match_df = strata_df[strata_df.frame.isin(predicate_matching_frames)]

            #         strata_std = strata_pred_match_df.sample_val.std()
            #         strata_pred_pos_rate = strata_pred_match_df.shape[0] / strata_df.shape[0] if strata_df.shape[0] > 0 else 0
            #         # split_val += np.sqrt(strata_pred_pos_rate) * strata_std
            #         split_vals.append(np.sqrt(strata_pred_pos_rate) * strata_std)

            #     return np.std(split_vals)
            
            # # CURRENTLY ASSUMES EXACTLY 3 STRATA
            # # compute grid of indices to try
            # set_of_stratas = []
            # min_proxy_val, max_proxy_val = np.min(sorted_proxy_values), np.max(sorted_proxy_values)
            # for lower_val in np.arange(min_proxy_val, max_proxy_val, (max_proxy_val - min_proxy_val)/20):
            #     for upper_val in np.arange(lower_val, max_proxy_val, (max_proxy_val - lower_val)/20):
            #         if lower_val < upper_val:
            #             set_of_stratas.append([lower_val, upper_val, 1.0001])

            # # perform grid search for best proxy split
            # best_val = np.inf
            # for strata in set_of_stratas:
            #     val = compute_split_val(strata, frame_proxy_df, predicate_matching_frames)
            #     if val < best_val:
            #         best_strata = strata
            #         best_val = val

        if 0 not in split_indices:
            self.strata = (
                [sorted_proxy_values[split_idx - 1] for split_idx in split_indices]
                if no_predicate
                # else best_strata
                else [sorted_proxy_values[split_idx - 1] for split_idx in split_indices]
            )
        else:
            print("NOT ENOUGH SAMPLES FOR STRATA INFERENCE")
            # self.strata = [0.3333, 0.6667, 1.0001]
            split_indices = np.linspace(len(self.all_proxy_values.values()), 0, self.S, endpoint=False, dtype=int)[::-1]
            self.strata = [sorted(self.all_proxy_values.values())[split_idx - 1] for split_idx in split_indices]

        # add small epsilon to each strata upper bound; we do this because our splits
        # have a non-trivial likelihood of falling on values that the proxy will
        # frequently output; if we set that exact value to be the upper bound then
        # samples with that proxy value will not be included in the strata due to
        # the fact that we use lower_bound <= proxy < upper_bound to determine placement
        for strata_idx in range(self.S):
            self.strata[strata_idx] += self.strata_epsilon

        # manually ensure that there's at least some min gap between strata values
        for strata_idx in range(self.S - 1):
            # note: we use >= because it's possible that three consecutive
            # strata could have the same value, in which case if we bump
            # the second strata to be self.min_strata_gap more than the first,
            # this will be greater than the value for the third strata
            if self.strata[strata_idx] >= self.strata[strata_idx + 1]:
                self.strata[strata_idx + 1] = self.strata[strata_idx] + self.min_strata_gap

        # manually set last strata to have upper limit of 1.0001
        self.strata[self.S - 1] = 1.0001

        self.all_strata.append(self.strata)

        # if we're in the pilot chunk we now need to split samples based on strata
        if fst_chunk_after_pilot:
            for oracle_pred, oracle_matches_predicate, frame in self.pilot_samples:
                proxy_val = self.all_proxy_values[frame]
                strata = self.get_strata(proxy_val, chunk=1, no_compute=True)

                # update relevant state
                self.samples[0][strata].append(oracle_pred)
                self.samples_match_predicate[0][strata].append(oracle_matches_predicate)
                self.sample_frames[0][strata].append(frame)

            frames = np.arange(0, self.pilot_end_frame, self.subsample)
            for frame in frames:
                proxy_val = self.all_proxy_values[frame]
                strata = self.get_strata(proxy_val, chunk=1, no_compute=True)
                self.counts[0][strata] += 1

    def sampling(self, strata_idx, oracle_pred, oracle_matches_predicate, chunk, frame):
        """
        Perform sampling within the specified strata for the given frame in the query.
        """
        # if we're in the pilot and infering strata; perform uniform sampling; use 0th strata by convention to store samples
        if self.infer_strata and chunk == 0:
            if frame in self.pilot_uniform_frames_to_sample:
                self.pilot_samples.append((oracle_pred, oracle_matches_predicate, frame))

            return

        # compute dynamic sampling allocation if we haven't yet
        strata_budget = None
        if self.dynamic:
            if chunk > 0 and not self.dynamic_computed[chunk]:  # second condition ensures we do this once
                # TODO: REVERT
                if False:
                    pass
                # if self.infer_strata and self.query.predicate != "":
                #     self.samples_per_strata[chunk] = [self.chunk_budgets[chunk] / self.S for _ in range(self.S)]

                #     # add back floored out samples; use original chunk budget for this
                #     if sum(self.samples_per_strata[chunk]) < self.chunk_budgets[chunk]:
                #         num_samples = int(self.chunk_budgets[chunk] - sum(self.samples_per_strata[chunk]))
                #         while num_samples > self.S:
                #             for strata_idx in range(self.S):
                #                 self.samples_per_strata[chunk][strata_idx] += 1
                #             num_samples = int(self.chunk_budgets[chunk] - sum(self.samples_per_strata[chunk]))

                #         indices = np.random.choice(np.arange(self.S), size=num_samples, replace=False)

                #         for strata_idx in indices:
                #             self.samples_per_strata[chunk][strata_idx] += 1

                else:
                    self.compute_dynamic_sample_allocation(chunk)

                self.dynamic_computed[chunk] = True

            # get the strata's dynamic sample budget
            strata_budget = int(self.samples_per_strata[chunk][strata_idx])

        else:
            strata_budget = self.samples_per_strata[0][strata_idx]

        # if reservoir isn't filled yet then add this frame to samples
        if len(self.samples[chunk][strata_idx]) < strata_budget:
            self.samples[chunk][strata_idx].append(oracle_pred)
            self.samples_match_predicate[chunk][strata_idx].append(oracle_matches_predicate)
            self.sample_frames[chunk][strata_idx].append(frame)

        # otherwise apply reservoir sampling logic
        else:
            sample_prob = strata_budget / self.counts[chunk][strata_idx]
            if random.random() < sample_prob:
                reservoir_idx = random.randint(0, strata_budget - 1)
                self.samples[chunk][strata_idx][reservoir_idx] = oracle_pred
                self.samples_match_predicate[chunk][strata_idx][reservoir_idx] = oracle_matches_predicate
                self.sample_frames[chunk][strata_idx][reservoir_idx] = frame

    def sample(self, proxy_val, oracle_pred, oracle_matches_predicate, frame):
        """
        Update internal logic of the sampling class and return a prediction.
        """
        # get chunk depending on frame
        chunk = None
        for chunk_idx in range(self.chunks):
            start = 0 if chunk_idx == 0 else self.chunk_end_frames[chunk_idx - 1]
            end = self.chunk_end_frames[chunk_idx] if chunk_idx < self.chunks - 1 else self.chunk_end_frames[chunk_idx] + 1
            if start <= frame and frame < end:
                chunk = chunk_idx
                break

        strata_idx = None
        if not self.infer_strata or chunk > 0:
            # get strata for sample based on proxy
            strata_idx = self.get_strata(proxy_val, chunk)

            # update counts depending on chunk
            self.counts[chunk][strata_idx] += 1

        # make call to reservoir sampling
        self.sampling(strata_idx, oracle_pred, oracle_matches_predicate, chunk, frame)

        # add proxy_val to list of all proxy values
        self.all_proxy_values[frame] = proxy_val


class StreamApproxSampling(BaseSampling):
    """
    An implementation of the StreamApprox OASRS sampling algorithm.
    """

    def __init__(self, strata: List[float], prior: List[float], oracle_budget: int, query: QueryType, agg_config: dict):
        """
        Initialize state needed to replicate OASRS logic.
        """
        self.S = len(strata)
        self.strata = sorted(strata)  # sort in increasing order if not already done
        self.budget = oracle_budget
        self.query = query
        self.agg_config = agg_config

        # list of samples to maintain for each strata
        self.samples = [[] for _ in range(self.S)]

        # state keeping track of whether each sample satisfies the query predicate
        self.samples_match_predicate = [[] for _ in range(self.S)]

        self.sample_frames = [[] for _ in range(self.S)]

        # weights per strata
        self.weights = [1 for _ in range(self.S)]

        # number of items in stream per strata
        self.counts = [0 for _ in range(self.S)]

        # # distribute budget evenly across strata
        # self.budget_per_strata = [
        #     (self.budget // self.S) + int(idx < self.budget % self.S)
        #     for idx in range(self.S)
        # ]
        # assert sum(self.budget_per_strata) == self.budget

        # distribute budget according to prior distribution; error up to rounding effects
        self.budget_per_strata = [
            round(self.budget * prior[idx])
            for idx in range(self.S)
        ]

        # list of time interval boundaries
        self.time_intervals = (
            list(np.linspace(
                start=query.start_frame,
                stop=query.end_frame,
                step=agg_config['window_len'],
                dtype=int
            )) + [query.end_frame]
            if agg_config['function'] == "window"
            else [np.inf]
        )

    def compute_prediction(self):
        """
        Return the predicted answer(s) to the given query.
        """
        # get samples matching predicate
        samples = self.get_samples()

        # print("-----------")
        # # print(f"samples: {samples}")
        # print(f"sums: {[np.sum(strata_samples) for strata_samples in samples]}")
        # print(f"samples total: {[len(strata_samples) for strata_samples in samples]}")
        # print(f"samples alloc: {[len(strata_samples)/5000 for strata_samples in samples]}")
        # print(f"means: {[np.mean(strata_samples) for strata_samples in samples]}")
        # print(f"weights: {self.weights}")
        # print(f"count total: {np.sum(self.counts)}")

        # with open('frames/sample_frames_oasrs.json','wt') as f:
        #     json.dump(self.sample_frames, f)

        prediction = None
        if self.agg_config['function'] == "mean":
            strata_prediction = []
            for strata_idx in range(self.S):
                strata_sum = np.sum(samples[strata_idx])
                strata_prediction.append(strata_sum * self.weights[strata_idx])
            
            prediction = np.sum(strata_prediction) / np.sum(self.counts)

        elif self.agg_config['function'] == "sum":
            strata_prediction = []
            for strata_idx in range(self.S):
                strata_sum = np.sum(samples[strata_idx])
                strata_prediction.append(strata_sum * self.weights[strata_idx])
            
            prediction = np.sum(strata_prediction)
        
        # print(f"prediction: {prediction}")

        return prediction

    def get_samples(self):
        """
        Return the samples generated by the sampling strategy; filter for
        the samples that actually match the predicate.
        """
        samples = [[] for _ in range(self.S)]
        for strata_idx in range(self.S):
            # get the strata's reservoir sample budget
            strata_num_samples = len(self.samples[strata_idx])

            for idx in range(strata_num_samples):
                sample = self.samples[strata_idx][idx]
                matches_predicate = self.samples_match_predicate[strata_idx][idx]

                # keep sample if it matches the predicate
                if matches_predicate:
                    samples[strata_idx].append(sample)

        return samples

    def get_strata(self, proxy_pred: float) -> int:
        """
        Return the index of the strata for the given proxy value.
        """
        for idx, upper_bound in enumerate(self.strata):
            if proxy_pred <= upper_bound:
                return idx

    def reservoir_sampling(self, strata_idx, oracle_pred, oracle_matches_predicate, frame):
        """
        Perform reservoir sampling within the specified strata for
        the given frame in the query.
        """
        # get the strata's reservoir sample budget
        strata_budget = self.budget_per_strata[strata_idx]

        # if reservoir isn't filled yet then add this frame to samples
        if len(self.samples[strata_idx]) < strata_budget:
            self.samples[strata_idx].append(oracle_pred)
            self.samples_match_predicate[strata_idx].append(oracle_matches_predicate)
            self.sample_frames[strata_idx].append(frame)

        # otherwise apply reservoir sampling logic
        else:
            sample_prob = strata_budget / self.counts[strata_idx]
            if random.random() < sample_prob:
                reservoir_idx = random.randint(0, strata_budget - 1)
                self.samples[strata_idx][reservoir_idx] = oracle_pred
                self.samples_match_predicate[strata_idx][reservoir_idx] = oracle_matches_predicate
                self.sample_frames[strata_idx][reservoir_idx] = frame

    def sample(self, proxy_val, oracle_pred, oracle_matches_predicate, frame):
        """
        Update internal logic of the sampling class and return a prediction.
        """
        # get strata based on proxy value
        strata_idx = self.get_strata(proxy_val)

        # update the count for this strata
        self.counts[strata_idx] += 1

        # resevoir sampling within strata
        self.reservoir_sampling(strata_idx, oracle_pred, oracle_matches_predicate, frame)

        # update weights
        self.weights[strata_idx] = (
            self.counts[strata_idx] / self.budget_per_strata[strata_idx]
            if (
                self.counts[strata_idx] > self.budget_per_strata[strata_idx]
                and self.budget_per_strata[strata_idx] > 0
            )
            else 1
        )
